import asyncio
import random
import os
import google.generativeai as genai
from telegram import Bot
from telegram.error import TelegramError

# ============ 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© (Ù…Ù† Railway) ============
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not TELEGRAM_TOKEN or not GEMINI_API_KEY:
    print("âŒ Ø®Ø·Ø£: ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØ© TELEGRAM_TOKEN Ùˆ GEMINI_API_KEY ÙÙŠ Railway Variables")
    exit(1)

genai.configure(api_key=GEMINI_API_KEY)

# ============ 2. ÙˆØ¸ÙŠÙØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù…Ø±ÙˆÙ†Ø© ============
def create_model(with_tools=True):
    """ØªØ­Ø§ÙˆÙ„ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø«ØŒ ÙˆØ¥Ø°Ø§ ÙØ´Ù„Øª ØªÙ†Ø´Ø¦ Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ Ø¹Ø§Ø¯ÙŠØ§Ù‹"""
    try:
        if with_tools:
            return genai.GenerativeModel(
                model_name='gemini-1.5-flash',
                tools=[{"google_search_retrieval": {}}]
            )
        return genai.GenerativeModel(model_name='gemini-1.5-flash')
    except:
        return genai.GenerativeModel(model_name='gemini-1.5-flash')

# ============ 3. Ø§Ù„ÙˆÙƒÙ„Ø§Ø¡ Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ÙˆÙ† ============
AGENTS = [
    {"name": "ğŸ” Ø¨Ø§Ø­Ø«_Ø£ÙˆÙ„ - Ø£Ø­Ù…Ø¯", "role": "Ø®Ø¨ÙŠØ± Ø§Ù„Ø¨Ø­Ø« ÙˆØ¬Ù„Ø¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©"},
    {"name": "ğŸ¤– Ù…Ø­Ù„Ù„_Ø¨ÙŠØ§Ù†Ø§Øª - Ø³Ø§Ø±Ø©", "role": "Ù…ØªØ®ØµØµØ© ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"},
    {"name": "ğŸŒ Ø¨Ø§Ø­Ø«_ÙˆÙŠØ¨ - Ø®Ø§Ù„Ø¯", "role": "Ø®Ø¨ÙŠØ± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ÙØªÙˆØ­Ø© ÙˆØ§Ù„Ù€ APIs"},
    {"name": "ğŸ“Š Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ - Ù…Ù†Ù‰", "role": "Ø®Ø¨ÙŠØ± Ø±Ø¨Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ§Ù„ØªØ®Ø·ÙŠØ·"},
    {"name": "âš¡ Ù…Ø·ÙˆØ±_Ø£ØªÙ…ØªØ© - ÙŠÙˆØ³Ù", "role": "Ø®Ø¨ÙŠØ± Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ÙˆØ§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©"}
]

conversation_history = []
discussion_active = False

# ============ 4. ÙˆØ¸ÙŠÙØ© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø°ÙƒÙŠ ============
async def get_ai_response(prompt):
    """ØªØ­Ø§ÙˆÙ„ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ù…Ø¹ Ø§Ù„Ø¨Ø­Ø«ØŒ ÙˆØ¥Ø°Ø§ ÙØ´Ù„Øª ØªÙˆÙ„Ø¯ Ø±Ø¯Ø§Ù‹ Ø¹Ø§Ø¯ÙŠØ§Ù‹ ÙÙˆØ±Ø§Ù‹"""
    try:
        # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ù…Ø¹ Ù…Ø­Ø±Ùƒ Ø¨Ø­Ø« Ø¬ÙˆØ¬Ù„
        model = create_model(with_tools=True)
        response = await asyncio.to_thread(model.generate_content, prompt)
        return response.text.strip()
    except Exception as e:
        print(f"Search failed, using fallback: {e}")
        try:
            # Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Ø±Ø¯ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø¨Ø§Ø´Ø± (Ø¨Ø¯ÙˆÙ† Ø¥Ù†ØªØ±Ù†Øª)
            model = create_model(with_tools=False)
            response = await asyncio.to_thread(model.generate_content, prompt)
            return response.text.strip()
        except Exception as e2:
            return f"Ø¹Ø°Ø±Ø§Ù‹ ÙŠØ§ Ø¹Ù†ØªØ±ØŒ ÙˆØ§Ø¬Ù‡Øª Ù…Ø´ÙƒÙ„Ø© ØªÙ‚Ù†ÙŠØ© ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {str(e2)[:50]}"

# ============ 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ============
async def handle_user_command(bot, chat_id, user_text):
    await bot.send_chat_action(chat_id=chat_id, action="typing")
    
    prompt = f"""Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ø±Ø³Ù„ Ø·Ù„Ø¨Ø§Ù‹: "{user_text}".
Ø¨ØµÙØªÙƒÙ… ÙØ±ÙŠÙ‚ ÙˆÙƒÙ„Ø§Ø¡ (Ø£Ø­Ù…Ø¯ØŒ Ø³Ø§Ø±Ø©ØŒ Ø®Ø§Ù„Ø¯ØŒ Ù…Ù†Ù‰ØŒ ÙŠÙˆØ³Ù)ØŒ 
Ù‚ÙˆÙ…ÙˆØ§ Ø¨ØªÙ†ÙÙŠØ° Ø§Ù„Ø·Ù„Ø¨ Ø£Ùˆ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„ÙŠÙ‡ Ø¨Ø¯Ù‚Ø© Ø¨Ù„Ø³Ø§Ù† Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø£Ù†Ø³Ø¨. 
Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø·Ù„Ø¨ ÙŠØ­ØªØ§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­Ø¯ÙŠØ«Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù…ÙˆØ§ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„."""
    
    response = await get_ai_response(prompt)
    await bot.send_message(chat_id=chat_id, text=f"âœ… **ØªÙ… Ø§Ù„ØªÙ†ÙÙŠØ°:**\n\n{response}", parse_mode="Markdown")

# ============ 6. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù†Ù‚Ø§Ø´ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ============
async def run_discussion(bot, chat_id):
    global discussion_active
    while discussion_active:
        agent = random.choice(AGENTS)
        history = "\n".join(conversation_history[-3:])
        prompt = f"Ø£Ù†Øª {agent['name']}. Ø´Ø§Ø±Ùƒ ÙÙŠ Ø§Ù„Ù†Ù‚Ø§Ø´ Ø­ÙˆÙ„ Ø£ØªÙ…ØªØ© Ø§Ù„Ø¨Ø­Ø« Ø¨Ø¬Ù…Ù„Ø© ÙˆØ§Ø­Ø¯Ø© Ø°ÙƒÙŠØ©. Ø§Ù„Ø³ÙŠØ§Ù‚: {history}"
        
        response = await get_ai_response(prompt)
        msg = f"*{agent['name']}:*\n{response}"
        
        try:
            await bot.send_message(chat_id=chat_id, text=msg, parse_mode="Markdown")
            conversation_history.append(f"{agent['name']}: {response}")
            if len(conversation_history) > 10: conversation_history.pop(0)
        except: break
        
        await asyncio.sleep(random.randint(60, 120))

# ============ 7. Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¨ÙˆØª ============
async def main():
    global discussion_active
    bot = Bot(token=TELEGRAM_TOKEN)
    last_update_id = None
    print("ğŸš€ Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬...")

    while True:
        try:
            updates = await bot.get_updates(offset=last_update_id, timeout=20)
            for update in updates:
                if not update.message or not update.message.text: continue
                last_update_id = update.update_id + 1
                
                chat_id = update.message.chat_id
                text = update.message.text

                if text == "/start":
                    discussion_active = True
                    asyncio.create_task(run_discussion(bot, chat_id))
                elif text == "/stop":
                    discussion_active = False
                    await bot.send_message(chat_id=chat_id, text="â¹ ØªÙˆÙ‚Ù Ø§Ù„Ù†Ù‚Ø§Ø´ Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ. Ø¨Ø§Ù†ØªØ¸Ø§Ø± Ø£ÙˆØ§Ù…Ø±Ùƒ.")
                elif text == "/status":
                    await bot.send_message(chat_id=chat_id, text="ğŸŸ¢ Ø§Ù„Ø¨ÙˆØª Ù…ØªØµÙ„ ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„.")
                else:
                    # Ø£ÙŠ Ø±Ø³Ø§Ù„Ø© Ø¹Ø§Ø¯ÙŠØ© ØªØ¹ØªØ¨Ø± Ø£Ù…Ø±Ø§Ù‹ Ù„Ù„ØªÙ†ÙÙŠØ°
                    await handle_user_command(bot, chat_id, text)

        except Exception as e:
            print(f"Main loop error: {e}")
            await asyncio.sleep(5)

if __name__ == "__main__":
    asyncio.run(main())
